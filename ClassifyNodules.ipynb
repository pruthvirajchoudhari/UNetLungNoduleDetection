{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ClassifyNodules.ipynb","provenance":[],"authorship_tag":"ABX9TyM/dRHy5UgThfa9gQAktRmz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"2QW0Ki4ecxKC"},"source":["from google.colab import drive\n","drive.mount('/content/Gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KS3YAfr1cylz"},"source":["cd /content/Gdrive/My Drive/LIDC-IDRI/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EFlmPLoEcnUo"},"source":["#FilePaths\n","dir= '/content/Gdrive/My Drive/LIDC-IDRI/'\n","datafolder=dir+'ProcessedData'\n","metafile=dir+\"LIDC-IDRI_MetaData.csv\"\n","list32file=dir+\"list3.2.csv\"\n","DOIpath=dir+'Dataset/'\n","unetweightspath=dir+\"modelweights/unet-weights-improvement.hdf5\"\n","truenoduleweightspath=dir+\"modelweights/truenodule-cnn-weights-improvement.hdf5\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mDgP8iOMdfuW"},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import dicom\n","import os\n","import scipy.ndimage\n","import time\n","from keras.callbacks import ModelCheckpoint\n","import h5py\n","from sklearn.cluster import KMeans\n","from skimage import measure, morphology\n","from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n","import cell_magic_wand as cmw\n","from glob import glob\n","import random\n","from sklearn.model_selection import train_test_split\n","import keras\n","from keras.models import Sequential,load_model,Model\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D, SpatialDropout2D\n","from keras.layers import Input, merge, UpSampling2D, BatchNormalization\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from keras import backend as K\n","from keras.utils import to_categorical\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras import backend as K\n","from keras.optimizers import Adam\n","K.set_image_dim_ordering('th') \n","nodulelocations=pd.read_csv(list32file)\n","meta=pd.read_csv(metafile)\n","\n","meta=meta.drop(meta[meta['Modality']!='CT'].index)\n","meta=meta.reset_index()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aU6K18AodgfL"},"source":["#Get folder names of CT data for each patient\n","patients=[DOIpath+meta['Patient Id'][i] for i in range(len(meta))]\n","datfolder=[]\n","for i in range(0,len(meta)-1):\n","    for path in os.listdir(patients[i]):\n","        if os.path.exists(patients[i]+'/'+path+'/'+meta['Series UID'][i]):\n","            datfolder.append(patients[i]+'/'+path+'/'+meta['Series UID'][i])\n","patients=datfolder"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xSMKQ3LXdqfD"},"source":["#Load nodules locations\n","smooth = 1.0\n","width = 32\n","\n","def dice_coef(y_true, y_pred):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n","def dice_coef_loss(y_true, y_pred):\n","    return -dice_coef(y_true, y_pred)\n","\n","def unet_model():\n","    inputs = Input((1, 512, 512))\n","    conv1 = Conv2D(width, 3, 3, activation='relu', border_mode='same')(inputs)\n","    conv1 = BatchNormalization(axis = 1)(conv1)\n","    conv1 = Conv2D(width, 3, 3, activation='relu', border_mode='same')(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","\n","    conv2 = Conv2D(width*2, 3, 3, activation='relu', border_mode='same')(pool1)\n","    conv2 = BatchNormalization(axis = 1)(conv2)\n","    conv2 = Conv2D(width*2, 3, 3, activation='relu', border_mode='same')(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","\n","    conv3 = Conv2D(width*4, 3, 3, activation='relu', border_mode='same')(pool2)\n","    conv3 = BatchNormalization(axis = 1)(conv3)\n","    conv3 = Conv2D(width*4, 3, 3, activation='relu', border_mode='same')(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","\n","    conv4 = Conv2D(width*8, 3, 3, activation='relu', border_mode='same')(pool3)\n","    conv4 = BatchNormalization(axis = 1)(conv4)\n","    conv4 = Conv2D(width*8, 3, 3, activation='relu', border_mode='same')(conv4)\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n","\n","    conv5 = Conv2D(width*16, 3, 3, activation='relu', border_mode='same')(pool4)\n","    conv5 = BatchNormalization(axis = 1)(conv5)\n","    conv5 = Conv2D(width*16, 3, 3, activation='relu', border_mode='same')(conv5)\n","\n","    up6 = merge([UpSampling2D(size=(2, 2))(conv5), conv4], mode='concat', concat_axis=1)\n","    conv6 = SpatialDropout2D(0.35)(up6)\n","    conv6 = Conv2D(width*8, 3, 3, activation='relu', border_mode='same')(conv6)\n","    conv6 = Conv2D(width*8, 3, 3, activation='relu', border_mode='same')(conv6)\n","\n","    up7 = merge([UpSampling2D(size=(2, 2))(conv6), conv3], mode='concat', concat_axis=1)\n","    conv7 = SpatialDropout2D(0.35)(up7)\n","    conv7 = Conv2D(width*4, 3, 3, activation='relu', border_mode='same')(conv7)\n","    conv7 = Conv2D(width*4, 3, 3, activation='relu', border_mode='same')(conv7)\n","\n","    up8 = merge([UpSampling2D(size=(2, 2))(conv7), conv2], mode='concat', concat_axis=1)\n","    conv8 = SpatialDropout2D(0.35)(up8)\n","    conv8 = Conv2D(width*2, 3, 3, activation='relu', border_mode='same')(conv8)\n","    conv8 = Conv2D(width*2, 3, 3, activation='relu', border_mode='same')(conv8)\n","\n","    up9 = merge([UpSampling2D(size=(2, 2))(conv8), conv1], mode='concat', concat_axis=1)\n","    conv9 = SpatialDropout2D(0.35)(up9)\n","    conv9 = Conv2D(width, 3, 3, activation='relu', border_mode='same')(conv9)\n","    conv9 = Conv2D(width, 3, 3, activation='relu', border_mode='same')(conv9)\n","    conv10 = Conv2D(1, 1, 1, activation='sigmoid')(conv9)\n","\n","    model = Model(input=inputs, output=conv10)\n","    model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef])\n","    return model\n","\n","model=unet_model()\n","model.load_weights(unetweightspath)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xa0p5noUdwOt"},"source":["# Load the scans in given folder path\n","def load_scan(path):\n","    slices = [dicom.read_file(path + '/' + s, force=True) for s in os.listdir(path) if s.endswith('.dcm')]\n","    slices.sort(key = lambda x: float(x.ImagePositionPatient[2]), reverse=True)\n","    try:\n","        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n","    except:\n","        slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n","        \n","    for s in slices:\n","        s.SliceThickness = slice_thickness\n","        \n","    return slices\n","\n","#convert to ndarray\n","def get_pixels_hu(slices):\n","    image = np.stack([s.pixel_array for s in slices])\n","    # Convert to int16 (from sometimes int16), \n","    # should be possible as values should always be low enough (<32k)\n","    image = image.astype(np.int16)\n","\n","    # Set outside-of-scan pixels to 0\n","    # The intercept is usually -1024, so air is approximately 0\n","    image[image == -2000] = 0\n","    \n","    # Convert to Hounsfield units (HU)\n","    for slice_number in range(len(slices)):\n","        \n","        intercept = slices[slice_number].RescaleIntercept\n","        slope = slices[slice_number].RescaleSlope\n","        \n","        if slope != 1:\n","            image[slice_number] = slope * image[slice_number].astype(np.float64)\n","            image[slice_number] = image[slice_number].astype(np.int16)\n","            \n","        image[slice_number] += np.int16(intercept)\n","    \n","    return np.array(image, dtype=np.int16)\n","\n","def processimage(img):\n","    #Standardize the pixel values\n","    mean = np.mean(img)\n","    std = np.std(img)\n","    img = img-mean\n","    img = img/std\n","    #plt.hist(img.flatten(),bins=200)\n","    #plt.show()\n","    #print(thresh_img[366][280:450])\n","    middle = img[100:400,100:400] \n","    mean = np.mean(middle)  \n","    max = np.max(img)\n","    min = np.min(img)\n","    #move the underflow bins\n","    img[img==max]=mean\n","    img[img==min]=mean\n","    kmeans = KMeans(n_clusters=2).fit(np.reshape(middle,[np.prod(middle.shape),1]))\n","    centers = sorted(kmeans.cluster_centers_.flatten())\n","    threshold = np.mean(centers)\n","    thresh_img = np.where(img<threshold,1.0,0.0)  # threshold the image\n","    eroded = morphology.erosion(thresh_img,np.ones([4,4]))\n","    dilation = morphology.dilation(eroded,np.ones([10,10]))\n","    labels = measure.label(dilation)\n","    label_vals = np.unique(labels)\n","    #plt.imshow(labels)\n","    #plt.show()\n","    labels = measure.label(dilation)\n","    label_vals = np.unique(labels)\n","    regions = measure.regionprops(labels)\n","    good_labels = []\n","    for prop in regions:\n","        B = prop.bbox\n","        if B[2]-B[0]<475 and B[3]-B[1]<475 and B[0]>40 and B[2]<472:\n","            good_labels.append(prop.label)\n","    mask = np.ndarray([512,512],dtype=np.int8)\n","    mask[:] = 0\n","    #\n","    #  The mask here is the mask for the lungs--not the nodes\n","    #  After just the lungs are left, we do another large dilation\n","    #  in order to fill in and out the lung mask \n","    #\n","    for N in good_labels:\n","        mask = mask + np.where(labels==N,1,0)\n","    mask = morphology.dilation(mask,np.ones([10,10])) # one last dilation\n","    return mask*img\n","\n","def processimagefromfile(ppix):\n","    processpix=np.ndarray([ppix.shape[0],512,512])\n","    for i in range(ppix.shape[0]):\n","        processpix[i]=processimage(ppix[i])\n","    return processpix\n","\n","#predict mask from images\n","def predictmask(images):\n","    images=images.reshape(images.shape[0],1,512,512)\n","    num_test=images.shape[0]\n","    imgs_mask_test = np.ndarray([num_test,1,512,512],dtype=np.float32)\n","    for i in range(num_test):\n","        imgs_mask_test[i] = model.predict([images[i:i+1]], verbose=0)[0]\n","    return imgs_mask_test\n","\n","#find number of slices where a nodule is detected\n","def getnoduleindex(imgs_mask_test):\n","    masksum=[np.sum(maskslice[0]) for maskslice in imgs_mask_test]\n","    return [i for i in range(len(masksum)) if masksum[i]>5]\n","\n","def nodule_coordinates(nodulelocations,meta):\n","    slices=nodulelocations[\"slice no.\"][nodulelocations.index[nodulelocations[\"case\"]==int(meta[\"Patient Id\"][-4:])]]\n","    xlocs=nodulelocations[\"x loc.\"][nodulelocations.index[nodulelocations[\"case\"]==int(meta[\"Patient Id\"][-4:])]]\n","    ylocs=nodulelocations[\"y loc.\"][nodulelocations.index[nodulelocations[\"case\"]==int(meta[\"Patient Id\"][-4:])]]\n","    nodulecoord=[]\n","    for i in range(len(slices)):\n","        nodulecoord.append([slices.values[i]-1,xlocs.values[i]-1,ylocs.values[i]-1])\n","    return nodulecoord\n","\n","#generate nodule or non-nodule labels for mask predictions\n","def truenodules(noduleindex,masks,nodulecoords):\n","    label=[]\n","    for ind in noduleindex:\n","        for cord in nodulecoords:\n","            if abs(ind-cord[0])<2:\n","                com=scipy.ndimage.center_of_mass(masks[ind])\n","                if abs(com[1]-cord[2])<2 and abs(com[2]-cord[1])<2:\n","                    label.append(True)\n","            else:\n","                label.append(False)\n","    return label\n","    \n","def slicecount(start,end):\n","    slicecounts=[]\n","    for i in range(start,end):\n","        if len(nodule_coordinates(nodulelocations,meta.iloc[i]))>0:\n","            patient_scan=load_scan(patients[i])\n","            slicecounts.append(len(patient_scan))\n","    return slicecounts"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TtI7X7YldznO"},"source":["start_time=time.time()\n","elapsed_time=0\n","totaltime=50000\n","noduleimages=np.ndarray([10000,512,512],dtype=np.float32)\n","nodulelabels=[]\n","nodulesensitivity=[]\n","index=0\n","coordcount=0\n","coordtruecount=0\n","nodulecount=0\n","noduletruecount=0\n","slicecounts=[]\n","thresh=-500 #lower HU threshold for nodule segmentation\n","for i in range(197,400):\n","    print(\"Processing patient#\",i,\"ETA:\",(totaltime-elapsed_time)/3600,\"hrs\")\n","    if len(nodule_coordinates(nodulelocations,meta.iloc[i]))>0:\n","        patient_scan=load_scan(patients[i])\n","        slicecounts.append(len(patient_scan))\n","        patient_pix=get_pixels_hu(patient_scan)\n","        processed_pix = processimagefromfile(patient_pix)\n","        coord = nodule_coordinates(nodulelocations,meta.iloc[i])\n","        print(coord)\n","        radius = nodulelocations[\"eq. diam.\"][nodulelocations.index[nodulelocations[\"case\"]==int(meta[\"Patient Id\"][i][-4:])]]\n","        print(radius)\n","        mask = predictmask(processed_pix)\n","        noduleindex = getnoduleindex(mask)        \n","        labels = np.zeros(len(noduleindex)).astype(np.bool)\n","        cordlabels=np.zeros(len(coord)).astype(np.bool)\n","        for j,cord in enumerate(coord): #loop through labeled nodules\n","            if radius.iloc[j]>5:\n","                nodulemask = cmw.cell_magic_wand(-patient_pix[int(cord[0])],[int(cord[2]),int(cord[1])],2,int(radius.iloc[j])+2)\n","                nodulepix=nodulemask*patient_pix[cord[0]]\n","                nodulepix[nodulepix<thresh]=0\n","                nodulepix[nodulepix!=0]=1\n","                nodulemask=nodulepix.astype(np.bool)\n","                for k,ind in enumerate(noduleindex): #loop through detected nodules\n","                    if abs(ind-cord[0])<2:\n","                        if np.sum(nodulemask*mask[ind][0])>1:\n","                            print(\"Nodule Detected at slice#\",ind,\"with actual coord\",cord)\n","                            labels[k] = True\n","                            cordlabels[j] = True\n","\n","        for j in range(len(coord)):\n","            nodulesensitivity.append(cordlabels[j])\n","            \n","        for k in range(len(noduleindex)):\n","            nodulelabels.append(labels[k])\n","            noduleimages[index]=processed_pix[noduleindex[k]]\n","            index+=1\n","        coordtruecount+=len(cordlabels[cordlabels==True])\n","        noduletruecount+=len(labels[labels==True])\n","        coordcount+=len(coord)\n","        nodulecount+=len(noduleindex)\n","        print(\"Sensitivity:\",coordtruecount/coordcount)\n","        print(\"Specificity:\",noduletruecount/nodulecount)\n","    elapsed_time=time.time()-start_time\n","    totaltime=elapsed_time/(i+1)*200\n","print(elapsed_time)\n","noduleimages=noduleimages[:len(nodulelabels)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1KchhqDVd8uH"},"source":["noduleimages=noduleimages[:len(nodulelabels)]\n","noduleimages=noduleimages.reshape([noduleimages.shape[0],1,512,512])\n","nodulelabels=np.array(nodulelabels)\n","np.save(\"noduleimages197-399.npy\",noduleimages)\n","np.save(\"nodulelabels197-399.npy\",nodulelabels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rx_Bm5iLd-8y"},"source":["nodulelabels=np.load(\"nodulelabels0-192.npy\")\n","nodulelabels=np.concatenate((nodulelabels,np.load(\"nodulelabels197-399.npy\")))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vQhlFQKHeCTC"},"source":["TP=len([nl for nl in nodulelabels if nl==True])\n","FP=len([nl for nl in nodulelabels if nl==False])\n","print(\"Number of True Positive nodules:\",TP)\n","print(\"Number of False Positive nodules:\",FP)\n","print(\"# of FPs per TP\",FP/TP)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yWEV7IkSeErL"},"source":["noduleimagestrue=np.load(\"noduleimagesv3.npy\")\n","falseind=[i for i in range(len(nodulelabels)) if nodulelabels[i]==False]\n","random.shuffle(falseind)\n","falseind=falseind[:noduleimagestrue.shape[0]]\n","noduleimagesfalse=np.array([noduleimages[i] for i in falseind])\n","del noduleimages\n","noduleimagesbalanced=np.concatenate((noduleimagestrue,noduleimagesfalse.reshape(noduleimagesfalse.shape[0],1,512,512)),axis=0)\n","nodulelabelsbalanced=[True]*noduleimagestrue.shape[0]+[False]*noduleimagesfalse.shape[0]\n","nodulelabelsbalanced=to_categorical(nodulelabelsbalanced,2)\n","del noduleimagestrue,noduleimagesfalse\n","Xtrain, Xtest, Ytrain, Ytest = train_test_split(noduleimagesbalanced,nodulelabelsbalanced,test_size=.30)\n","del noduleimagesbalanced, nodulelabelsbalanced"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QptBrFr8eHDC"},"source":["#classify as nodule or non-nodule\n","input_shape=(1,512,512)\n","num_classes=2\n","model = Sequential()\n","model.add(Conv2D(8, kernel_size=(3, 3),\n","                 activation='relu',\n","                 input_shape=input_shape))\n","model.add(Conv2D(16, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","model.add(Flatten())\n","model.add(Dense(32, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.compile(loss=keras.losses.binary_crossentropy,\n","              optimizer=Adam(lr=1e-5),\n","              metrics=['accuracy'])\n","\n","checkpoint = ModelCheckpoint(truenoduleweightspath, monitor='loss', verbose=1, save_best_only=True)\n","\n","history=model.fit(Xtrain, Ytrain, batch_size=4, epochs=20, verbose=1, shuffle=True, callbacks=[checkpoint], validation_data=(Xtest,Ytest))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bqU50QKBeJZx"},"source":["plt.plot(history.history['loss'], color='b')\n","plt.plot(history.history['val_loss'], color='g')\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Log Loss\")\n","plt.legend([\"Train\", \"Validation\"])\n","plt.show()\n","plt.plot(history.history['acc'], color='b')\n","plt.plot(history.history['val_acc'], color='g')\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Accuracy\")\n","plt.legend([\"Train\", \"Validation\"])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3nMduREKeLk1"},"source":["XtestTrue=np.array([Xtest[i] for i in range(Ytest.shape[0]) if Ytest[i,1]==1])\n","YtestTrue=np.array([Ytest[i] for i in range(Ytest.shape[0]) if Ytest[i,1]==1])\n","XtestFalse=np.array([Xtest[i] for i in range(Ytest.shape[0]) if Ytest[i,1]==0])\n","YtestFalse=np.array([Ytest[i] for i in range(Ytest.shape[0]) if Ytest[i,1]==0])\n","\n","scoretrue=model.evaluate(XtestTrue,YtestTrue)"],"execution_count":null,"outputs":[]}]}